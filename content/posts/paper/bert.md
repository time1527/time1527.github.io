---
date: '2024-12-26T22:00:00+08:00'
draft: false
title: 'BERT笔记'
tags: ["encoder","预训练+微调","BERT"]
categories: ["大模型"]
---

[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://xves6ft58q.feishu.cn/docx/Au3XddmPPoE4KYxaMOxc2t2HnNc?from=from_copylink)
